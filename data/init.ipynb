{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "folder_aws_path = \"aws/\"\n",
    "folder_build_path = \"build/\"\n",
    "folder_build_config_path = \"build/config/\"\n",
    "folder_build_task_path = \"build/task/\"\n",
    "folder_build_mturk_path = \"build/mturk/\"\n",
    "folder_build_skeleton_path = \"build/skeleton/\"\n",
    "folder_tasks_path = \"tasks/\"\n",
    "\n",
    "def serialize_json(folder, filename, data):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "    with open(f\"{folder}/{filename}\", 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4, default=str)\n",
    "        f.close()\n",
    "\n",
    "def remove_json(folder, filename):\n",
    "    os.remove(f\"{folder}/{filename}\")\n",
    "\n",
    "def read_json(path):\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\", encoding=\"utf8\") as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "    else:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Section 1 - Environment variables loading"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "env_path = Path('.') / '.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "task_name = os.getenv('task_name')\n",
    "batch_name = os.getenv('batch_name')\n",
    "admin_user = os.getenv('admin_user')\n",
    "admin_password = os.getenv('admin_password')\n",
    "\n",
    "aws_account_id = os.getenv('aws_account_id')\n",
    "aws_sdk_access_id = os.getenv('aws_sdk_access_id')\n",
    "aws_sdk_access_secret = os.getenv('aws_sdk_access_secret')\n",
    "\n",
    "aws_region = os.getenv('aws_region')\n",
    "aws_private_bucket = os.getenv('aws_private_bucket')\n",
    "aws_deploy_bucket = os.getenv('aws_deploy_bucket')\n",
    "\n",
    "bing_api_key = os.getenv('bing_api_key')\n",
    "\n",
    "# print(\"Printing env vars values:\")\n",
    "# print(f\"AWS ACCOUNT ID: {aws_account_id}\")\n",
    "# print(f\"AWS SDK ACCESS ID: {aws_sdk_access_id}\")\n",
    "# print(f\"AWS SDK ACCESS SECRET: {aws_sdk_access_secret}\")\n",
    "# print(f\"AWS REGION: {aws_region}\")\n",
    "# print(f\"AWS PRIVATE BUCKET: {aws_private_bucket}\")\n",
    "# print(f\"AWS DEPLOY BUCKET: {aws_deploy_bucket}\")\n",
    "# print(f\"BING API KEY: {bing_api_key}\")\n",
    "# print(f\"TASK NAME: {task_name}\")\n",
    "# print(f\"BATCH NAME: {batch_name}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Section 2 - Setting up IAM policies and identity\n",
    "### build/aws"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crowd workers IAM policy with ARN arn:aws:iam::269559900417:policy/crowd-workers-dev retrieved, HTTP STATUS CODE: 200.\n",
      "Crowd worker user worker-dev retrieved, HTTP STATUS CODE: 200.\n",
      "Policy with ARN arn:aws:iam::269559900417:policy/crowd-workers-dev attached to user worker-dev, HTTP STATUS CODE: 200\n",
      "Key data found on disk and loaded.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "iam = boto3.client('iam')\n",
    "\n",
    "crowd_workers_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"allowWorkerInteraction\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:PutObject\",\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                f\"arn:aws:s3:::{aws_private_bucket}\",\n",
    "                f\"arn:aws:s3:::{aws_private_bucket}/*\",\n",
    "                f\"arn:aws:s3:::{aws_deploy_bucket}\",\n",
    "                f\"arn:aws:s3:::{aws_deploy_bucket}/*\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "policy = None\n",
    "try:\n",
    "    policy = iam.create_policy(\n",
    "        PolicyName='crowd-workers-dev',\n",
    "        PolicyDocument=json.dumps(crowd_workers_policy)\n",
    "    )\n",
    "    print(\n",
    "        f\"Crowd workers IAM policy with ARN {policy['Policy']['Arn']} creation completed, HTTP STATUS CODE: {policy['ResponseMetadata']['HTTPStatusCode']}.\")\n",
    "except (iam.exceptions.NoSuchEntityException, iam.exceptions.EntityAlreadyExistsException) as exception:\n",
    "    policy = iam.get_policy(PolicyArn=f\"arn:aws:iam::{aws_account_id}:policy/crowd-workers-dev\")\n",
    "    print(\n",
    "        f\"Crowd workers IAM policy with ARN {policy['Policy']['Arn']} retrieved, HTTP STATUS CODE: {policy['ResponseMetadata']['HTTPStatusCode']}.\")\n",
    "serialize_json(folder_aws_path, f\"policy_{policy['Policy']['PolicyName']}.json\", policy)\n",
    "\n",
    "user = None\n",
    "try:\n",
    "    user = iam.create_user(UserName=\"worker-dev\")\n",
    "    print(\n",
    "        f\"Crowd workers user {user['User']['UserName']} created, HTTP STATUS CODE: {user['ResponseMetadata']['HTTPStatusCode']}.\")\n",
    "except (iam.exceptions.NoSuchEntityException, iam.exceptions.EntityAlreadyExistsException) as exception:\n",
    "    user = iam.get_user(UserName=\"worker-dev\")\n",
    "    print(\n",
    "        f\"Crowd worker user {user['User']['UserName']} retrieved, HTTP STATUS CODE: {user['ResponseMetadata']['HTTPStatusCode']}.\")\n",
    "serialize_json(folder_aws_path, f\"user_{user['User']['UserName']}_data.json\", user)\n",
    "\n",
    "response = iam.attach_user_policy(UserName=user['User']['UserName'], PolicyArn=policy['Policy']['Arn'])\n",
    "policy = iam.get_policy(PolicyArn=f\"{policy['Policy']['Arn']}\")\n",
    "print(\n",
    "    f\"Policy with ARN {policy['Policy']['Arn']} attached to user {user['User']['UserName']}, HTTP STATUS CODE: {user['ResponseMetadata']['HTTPStatusCode']}\")\n",
    "\n",
    "keys = []\n",
    "paginator = iam.get_paginator('list_access_keys')\n",
    "for found_keys in paginator.paginate(UserName=user['User']['UserName']):\n",
    "    for (index, key) in enumerate(found_keys['AccessKeyMetadata']):\n",
    "        keyData = read_json(f\"{folder_aws_path}user_{user['User']['UserName']}_access_key_{key['AccessKeyId']}.json\")\n",
    "        if keyData:\n",
    "            keys.append(keyData)\n",
    "        else:\n",
    "            response = iam.delete_access_key(UserName=user['User']['UserName'], AccessKeyId=key['AccessKeyId'])\n",
    "            print(f\"Key {index} data not found on disk; deleting it on AWS, HTTP STATUS CODE: {response['ResponseMetadata']['HTTPStatusCode']}\")\n",
    "\n",
    "if len(keys) < 2:\n",
    "    key = iam.create_access_key(UserName=user['User']['UserName'])\n",
    "    serialize_json(folder_aws_path, f\"user_{user['User']['UserName']}_access_key_{key['AccessKey']['AccessKeyId']}.json\", key)\n",
    "    print(f\"Access key with for user {user['User']['UserName']} created, HTTP STATUS CODE: {key['ResponseMetadata']['HTTPStatusCode']}.\")\n",
    "    keys.append(key)\n",
    "    if not os.path.exists(f\"{folder_aws_path}user_{user['User']['UserName']}_access_key_{key['AccessKey']['AccessKeyId']}.json\"):\n",
    "        serialize_json(folder_aws_path, f\"user_{user['User']['UserName']}_access_key_{key['AccessKey']['AccessKeyId']}.json\", key)\n",
    "        print(f\"Access key for user {user['User']['UserName']} created, HTTP STATUS CODE: {key['ResponseMetadata']['HTTPStatusCode']}.\")\n",
    "\n",
    "key_selected = random.choice(keys)\n",
    "key_data = read_json(f\"{folder_aws_path}user_{user['User']['UserName']}_access_key_{key_selected['AccessKey']['AccessKeyId']}.json\")\n",
    "\n",
    "print(\"Key data found on disk and loaded.\")\n",
    "\n",
    "aws_worker_access_id = key_data['AccessKey']['AccessKeyId']\n",
    "aws_worker_access_secret = key_data['AccessKey']['SecretAccessKey']\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Section 3 - Private and deploy bucket creation\n",
    "### build/aws"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- INITIALIZING PRIVATE BUCKET private-bucket-test-fdssfsdfdssdds ----------\n",
      "Bucket already present, HTTP STATUS CODE: 409.\n",
      "Public access blocked, HTTP STATUS CODE: 200.\n",
      "Policy already present, HTTP STATUS CODE: 200.\n",
      "CORS Configuration already present, HTTP STATUS CODE: 200.\n",
      "---------- INITIALIZATION COMPLETED ----------\n",
      "---------- INITIALIZING DEPLOY BUCKET deploy-bucket-test-fsfddfsfdsfsfsffssfdfsdfsfsdfsd ----------\n",
      "Bucket already present, HTTP STATUS CODE: 409.\n",
      "Policy already present, HTTP STATUS CODE: 200.\n",
      "---------- INITIALIZATION COMPLETED ----------\n"
     ]
    }
   ],
   "source": [
    "s3_client = boto3.client('s3', aws_access_key_id=aws_sdk_access_id, aws_secret_access_key=aws_sdk_access_secret)\n",
    "s3_resource = boto3.resource('s3')\n",
    "\n",
    "buckets = []\n",
    "for bucket in s3_resource.buckets.all():\n",
    "    buckets.append(bucket.name)\n",
    "\n",
    "print(f\"---------- INITIALIZING PRIVATE BUCKET {aws_private_bucket} ----------\")\n",
    "\n",
    "try:\n",
    "    private_bucket = s3_client.create_bucket(\n",
    "        Bucket=aws_private_bucket,\n",
    "        CreateBucketConfiguration={\n",
    "            'LocationConstraint': aws_region\n",
    "        }\n",
    "    )\n",
    "    print(f\"Bucket creation completed, HTTP STATUS CODE: {private_bucket['ResponseMetadata']['HTTPStatusCode']}.\")\n",
    "except s3_client.exceptions.BucketAlreadyOwnedByYou as error:\n",
    "    private_bucket = s3_resource.Bucket(aws_private_bucket)\n",
    "    print(f\"Bucket already present, HTTP STATUS CODE: {error.response['ResponseMetadata']['HTTPStatusCode']}.\")\n",
    "serialize_json(folder_aws_path, f\"bucket_{aws_private_bucket}.json\", private_bucket)\n",
    "\n",
    "response = s3_client.put_public_access_block(\n",
    "    Bucket=aws_private_bucket,\n",
    "    PublicAccessBlockConfiguration={\n",
    "        'BlockPublicAcls': True,\n",
    "        'IgnorePublicAcls': True,\n",
    "        'BlockPublicPolicy': True,\n",
    "        'RestrictPublicBuckets': True\n",
    "    },\n",
    ")\n",
    "print(f\"Public access blocked, HTTP STATUS CODE: {response['ResponseMetadata']['HTTPStatusCode']}.\")\n",
    "\n",
    "private_bucket_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Id\": \"private-bucket-policy\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"allow-bucket-interaction\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"AWS\": f\"arn:aws:iam::{aws_account_id}:user/{user['User']['UserName']}\"\n",
    "            },\n",
    "            \"Action\": [\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:PutObject\",\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                f\"arn:aws:s3:::{aws_private_bucket}\",\n",
    "                f\"arn:aws:s3:::{aws_private_bucket}/*\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "try:\n",
    "    policy = s3_client.get_bucket_policy(Bucket=aws_private_bucket)\n",
    "    policy['Policy'] = json.loads(policy['Policy'])\n",
    "    print(f\"Policy already present, HTTP STATUS CODE: {response['ResponseMetadata']['HTTPStatusCode']}.\")\n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'NoSuchBucketPolicy':\n",
    "        response = s3_client.put_bucket_policy(Bucket=aws_private_bucket, Policy=json.dumps(private_bucket_policy))\n",
    "        print(f\"Policy configuration completed, HTTP STATUS CODE: {response['ResponseMetadata']['HTTPStatusCode']}.\")\n",
    "    policy = s3_client.get_bucket_policy(Bucket=aws_private_bucket)\n",
    "    policy['Policy'] = json.loads(policy['Policy'])\n",
    "serialize_json(folder_aws_path, f\"bucket_{aws_private_bucket}_policy.json\", policy)\n",
    "\n",
    "cors_configuration = {\n",
    "    'CORSRules': [{\n",
    "        'AllowedHeaders': ['*'],\n",
    "        'AllowedMethods': ['GET', 'HEAD', 'PUT'],\n",
    "        'AllowedOrigins': ['*'],\n",
    "        'ExposeHeaders': [],\n",
    "        'MaxAgeSeconds': 3000\n",
    "    }]\n",
    "}\n",
    "\n",
    "try:\n",
    "    cors_configuration = s3_client.get_bucket_cors(Bucket=aws_private_bucket)\n",
    "    print(f\"CORS Configuration already present, HTTP STATUS CODE: {response['ResponseMetadata']['HTTPStatusCode']}.\")\n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'NoSuchCORSConfiguration':\n",
    "        response = s3_client.put_bucket_cors(Bucket=aws_private_bucket, CORSConfiguration=cors_configuration)\n",
    "        print(f\"CORS configuration completed, HTTP STATUS CODE: {response['ResponseMetadata']['HTTPStatusCode']}.\")\n",
    "    cors_configuration = s3_client.get_bucket_cors(Bucket=aws_private_bucket)\n",
    "    cors_configuration['CORSRules'] = json.loads(cors_configuration['CORSRules'])\n",
    "    print(cors_configuration)\n",
    "serialize_json(folder_aws_path, f\"bucket_{aws_private_bucket}_cors.json\", cors_configuration)\n",
    "\n",
    "print(f\"---------- INITIALIZATION COMPLETED ----------\")\n",
    "\n",
    "print(f\"---------- INITIALIZING DEPLOY BUCKET {aws_deploy_bucket} ----------\")\n",
    "\n",
    "try:\n",
    "    deploy_bucket = s3_client.create_bucket(\n",
    "        Bucket=aws_deploy_bucket,\n",
    "        CreateBucketConfiguration={\n",
    "            'LocationConstraint': aws_region\n",
    "        }\n",
    "    )\n",
    "    print(f\"Bucket creation completed, HTTP STATUS CODE: {deploy_bucket['ResponseMetadata']['HTTPStatusCode']}.\")\n",
    "except s3_client.exceptions.BucketAlreadyOwnedByYou as error:\n",
    "    deploy_bucket = s3_resource.Bucket(aws_deploy_bucket)\n",
    "    print(f\"Bucket already present, HTTP STATUS CODE: {error.response['ResponseMetadata']['HTTPStatusCode']}.\")\n",
    "serialize_json(folder_aws_path, f\"bucket_{aws_deploy_bucket}.json\", deploy_bucket)\n",
    "\n",
    "deploy_bucket_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Id\": \"deploy-bucket-policy\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"allow-bucket-interaction\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"AWS\": f\"arn:aws:iam::{aws_account_id}:user/{user['User']['UserName']}\"\n",
    "            },\n",
    "            \"Action\": [\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:PutObject\",\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                f\"arn:aws:s3:::{aws_deploy_bucket}\",\n",
    "                f\"arn:aws:s3:::{aws_deploy_bucket}/*\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "try:\n",
    "    policy = s3_client.get_bucket_policy(Bucket=aws_deploy_bucket)\n",
    "    policy['Policy'] = json.loads(policy['Policy'])\n",
    "    print(f\"Policy already present, HTTP STATUS CODE: {response['ResponseMetadata']['HTTPStatusCode']}.\")\n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'NoSuchBucketPolicy':\n",
    "        response = s3_client.put_bucket_policy(Bucket=aws_deploy_bucket, Policy=json.dumps(deploy_bucket_policy))\n",
    "        print(f\"Policy configuration completed, HTTP STATUS CODE: {response['ResponseMetadata']['HTTPStatusCode']}.\")\n",
    "    policy = s3_client.get_bucket_policy(Bucket=aws_deploy_bucket)\n",
    "    policy['Policy'] = json.loads(policy['Policy'])\n",
    "serialize_json(folder_aws_path, f\"bucket_{aws_private_bucket}_policy.json\", policy)\n",
    "\n",
    "print(f\"---------- INITIALIZATION COMPLETED ----------\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Section 4 - Environment file generation\n",
    "### build/environments"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File for PRODUCTION environment generated at path: build/environments/environment.prod.ts\n",
      "File for DEVELOPMENT environment generated at path: build/environments/environment.ts\n"
     ]
    }
   ],
   "source": [
    "environment_development = f\"{folder_build_path}environments/environment.ts\"\n",
    "environment_production = f\"{folder_build_path}environments/environment.prod.ts\"\n",
    "\n",
    "environment_dict = {\n",
    "    \"production\": 'true',\n",
    "    \"configuration_local\": 'false',\n",
    "    \"taskName\": task_name,\n",
    "    \"batchName\": batch_name,\n",
    "    \"region\": aws_region,\n",
    "    \"bucket\": aws_private_bucket,\n",
    "    \"aws_id_key\": aws_worker_access_id,\n",
    "    \"aws_secret_key\": aws_worker_access_secret,\n",
    "    \"bing_api_key\": bing_api_key\n",
    "}\n",
    "\n",
    "with open(environment_production, 'w') as file:\n",
    "    print(\"export const environment = {\", file=file)\n",
    "    for (env_var, value) in environment_dict.items():\n",
    "        if env_var == 'production' or env_var == 'configuration_local':\n",
    "            print(f\"\\t{env_var}: {value},\", file=file)\n",
    "        else:\n",
    "            print(f\"\\t{env_var}: \\\"{value}\\\",\", file=file)\n",
    "    print(\"};\", file=file)\n",
    "\n",
    "print(\"File for PRODUCTION environment generated at path:\", environment_production)\n",
    "\n",
    "environment_dict = {\n",
    "    \"production\": 'false',\n",
    "    \"configuration_local\": 'true',\n",
    "    \"taskName\": task_name,\n",
    "    \"batchName\": batch_name,\n",
    "    \"region\": aws_region,\n",
    "    \"bucket\": aws_private_bucket,\n",
    "    \"aws_id_key\": aws_worker_access_id,\n",
    "    \"aws_secret_key\": aws_worker_access_secret,\n",
    "    \"bing_api_key\": bing_api_key\n",
    "}\n",
    "\n",
    "with open(environment_development, 'w') as file:\n",
    "    print(\"export const environment = {\", file=file)\n",
    "    for (env_var, value) in environment_dict.items():\n",
    "        if env_var == 'production' or env_var == 'configuration_local':\n",
    "            print(f\"\\t{env_var}: {value},\", file=file)\n",
    "        else:\n",
    "            print(f\"\\t{env_var}: \\\"{value}\\\",\", file=file)\n",
    "    print(\"};\", file=file)\n",
    "\n",
    "print(\"File for DEVELOPMENT environment generated at path:\", environment_development)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Section 5 - admin.json file generation\n",
    "### Reference: https://pycryptodome.readthedocs.io/en/latest/src/cipher/classic.html#cbc-mode\n",
    "### build/config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admin.json file generated at path: build/admin.json\n"
     ]
    }
   ],
   "source": [
    "from base64 import b64encode\n",
    "from Crypto.Cipher import AES\n",
    "from Crypto.Util.Padding import pad\n",
    "\n",
    "admin_file = f\"{folder_build_config_path}admin.json\"\n",
    "\n",
    "data = {\"username\": admin_user}\n",
    "key = admin_password.encode()\n",
    "cipher = AES.new(key, AES.MODE_CBC)\n",
    "ct_bytes = cipher.encrypt(pad(json.dumps(data).encode(), AES.block_size))\n",
    "init_vector = b64encode(cipher.iv).decode('utf-8')\n",
    "cypher_text = b64encode(ct_bytes).decode('utf-8')\n",
    "data = [{\"crypt\": cypher_text}]\n",
    "with open(admin_file, 'w') as f:\n",
    "    json.dump(data, f, indent=4)\n",
    "\n",
    "print(\"admin.json file generated at path:\", admin_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Section 6 - document.ts file generation\n",
    "### build/skeleton"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import textwrap\n",
    "\n",
    "hits_file = f\"{folder_build_task_path}hits.json\"\n",
    "document_interface = f\"{folder_build_skeleton_path}document-temp.ts\"\n",
    "\n",
    "hits = read_json(hits_file)\n",
    "sample_element = hits.pop()['documents'].pop()\n",
    "\n",
    "if not 'id' in sample_element.keys():\n",
    "    raise Exception(\"Please, make sure that your hits.json file contains an attributed called \\\"id\\\"\")\n",
    "\n",
    "# This class provides a representation of a single document stored in single hit stored in the Amazon S3 bucket.\n",
    "# The attribute <document_index> is additional and should not be touched and passed in the constructor.\n",
    "# Each field of such Document must be mapped to an attribute of this class and set up in the constructor as it is shown.\n",
    "\n",
    "with open(document_interface, 'w') as file:\n",
    "    print(\"export class Document {\", file=file)\n",
    "    print(\"\", file=file)\n",
    "    wrapper = textwrap.TextWrapper(initial_indent='\\t\\t', subsequent_indent='\\t\\t')\n",
    "    print(wrapper.fill(\"index: number;\"), file=file)\n",
    "    print(wrapper.fill(\"countdownExpired: boolean;\"), file=file)\n",
    "    for attribute, value in sample_element.items():\n",
    "        if isinstance(value, list):\n",
    "            print(wrapper.fill(f\"{attribute}: Array<JSON>;\"), file=file)\n",
    "        elif isinstance(value, int) or isinstance(value, float):\n",
    "            print(wrapper.fill(f\"{attribute}: number;\"), file=file)\n",
    "        else:\n",
    "            print(wrapper.fill(f\"{attribute}: string;\"), file=file)\n",
    "    print(\"\", file=file)\n",
    "    print(wrapper.fill(f\"constructor (\"), file=file)\n",
    "    wrapper = textwrap.TextWrapper(initial_indent='\\t\\t\\t', subsequent_indent='\\t\\t\\t')\n",
    "    print(\"\", file=file)\n",
    "    print(wrapper.fill(\"index: number,\"), file=file)\n",
    "    print(wrapper.fill(\"data: JSON\"), file=file)\n",
    "    print(\"\", file=file)\n",
    "    wrapper = textwrap.TextWrapper(initial_indent='\\t\\t', subsequent_indent='\\t\\t')\n",
    "    print(wrapper.fill(\") {\"), file=file)\n",
    "    print(\"\", file=file)\n",
    "    wrapper = textwrap.TextWrapper(initial_indent='\\t\\t\\t', subsequent_indent='\\t\\t\\t')\n",
    "    print(wrapper.fill(\"this.index = index\"), file=file)\n",
    "    for attribute, value in sample_element.items():\n",
    "        if isinstance(value, list):\n",
    "            print(wrapper.fill(f\"for (let index = 0; index < data[\\\"{attribute}\\\"].length; index++) this.{attribute}.push(data[\\\"{attribute}\\\"][index])\"), file=file)\n",
    "        else:\n",
    "            wrapper = textwrap.TextWrapper(initial_indent='\\t\\t\\t', subsequent_indent='\\t\\t\\t')\n",
    "            print(wrapper.fill(f\"this.{attribute} = data[\\\"{attribute}\\\"]\"), file=file)\n",
    "    wrapper = textwrap.TextWrapper(initial_indent='\\t\\t', subsequent_indent='\\t\\t')\n",
    "    print(\"\", file=file)\n",
    "    print(wrapper.fill(\"}\"), file=file)\n",
    "    print(\"\", file=file)\n",
    "    print(\"}\", file=file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Section 7 - Amazon Mechanical Turk assets generation\n",
    "### build/mturk"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon Mechanical Turk landing page generated at path:\n",
      "build/mturk/index.html\n",
      "Reading hits file from path:\n",
      "build/task/hits.json\n",
      "Tokens for 34 hits required by Amazon Mechanical Turk generated at path:\n",
      "build/mturk/tokens.csv\n"
     ]
    }
   ],
   "source": [
    "from mako.template import Template\n",
    "\n",
    "model = Template(filename=f\"{folder_build_mturk_path}model.html\")\n",
    "mturk_page = model.render(\n",
    "    aws_region = aws_region,\n",
    "    aws_deploy_bucket = aws_deploy_bucket,\n",
    "    task_name = task_name,\n",
    "    batch_name = batch_name\n",
    ")\n",
    "mturk_page_file = f\"{folder_build_mturk_path}index.html\"\n",
    "with open(mturk_page_file, 'w') as file:\n",
    "    print(mturk_page, file=file)\n",
    "\n",
    "print(f\"Amazon Mechanical Turk landing page generated at path:\")\n",
    "print(mturk_page_file)\n",
    "\n",
    "hits_file = f\"{folder_build_task_path}hits.json\"\n",
    "mturk_tokens_file = f\"{folder_build_mturk_path}tokens.csv\"\n",
    "print(f\"Reading hits file from path:\")\n",
    "print(hits_file)\n",
    "hits = read_json(hits_file)\n",
    "token_df = pd.DataFrame(columns=[\"token_input\", \"token_output\"])\n",
    "for hit in hits:\n",
    "    token_df = token_df.append({\n",
    "        \"token_input\": hit['token_input'],\n",
    "        \"token_output\": hit['token_output']\n",
    "    }, ignore_index=True)\n",
    "token_df.to_csv(mturk_tokens_file, index=False)\n",
    "print(f\"Tokens for {len(hits)} hits required by Amazon Mechanical Turk generated at path:\")\n",
    "print(mturk_tokens_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}