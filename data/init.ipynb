{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from rich.console import Console\n",
    "from rich.panel import Panel\n",
    "from rich import inspect\n",
    "from rich.text import Text\n",
    "from rich.progress import Progress\n",
    "import json\n",
    "\n",
    "console = Console()\n",
    "\n",
    "folder_aws_path = \"aws/\"\n",
    "folder_build_path = \"build/\"\n",
    "folder_build_config_path = \"build/config/\"\n",
    "folder_build_task_path = \"build/task/\"\n",
    "folder_build_mturk_path = \"build/mturk/\"\n",
    "folder_build_deploy_path = \"build/deploy/\"\n",
    "folder_build_skeleton_path = \"build/skeleton/\"\n",
    "folder_tasks_path = \"tasks/\"\n",
    "\n",
    "def serialize_json(folder, filename, data):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "    with open(f\"{folder}/{filename}\", 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4, default=str)\n",
    "        f.close()\n",
    "\n",
    "def remove_json(folder, filename):\n",
    "    os.remove(f\"{folder}/{filename}\")\n",
    "\n",
    "def read_json(path):\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\", encoding=\"utf8\") as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "    else:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Section 1 - Environment variables loading\n",
    "\n",
    "Remember to restart Jupyter if you edit environment variables values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from distutils.util import strtobool\n",
    "\n",
    "env_path = Path('.') / '.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "task_name = os.getenv('task_name')\n",
    "batch_name = os.getenv('batch_name')\n",
    "admin_user = os.getenv('admin_user')\n",
    "admin_password = os.getenv('admin_password')\n",
    "deploy_config = strtobool(os.getenv('deploy_config'))\n",
    "\n",
    "aws_region = os.getenv('aws_region')\n",
    "aws_private_bucket = os.getenv('aws_private_bucket')\n",
    "aws_deploy_bucket = os.getenv('aws_deploy_bucket')\n",
    "\n",
    "bing_api_key = os.getenv('bing_api_key')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Section 2 - Setting up IAM policies and identity\n",
    "### build/aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "iam = boto3.client('iam')\n",
    "iam_resource = boto3.resource('iam')\n",
    "\n",
    "console.rule(\"Root user identity\")\n",
    "\n",
    "root_user = iam_resource.CurrentUser()\n",
    "aws_account_id = root_user.arn.split(':')[4]\n",
    "\n",
    "console.print(f\"ID: [bold cyan on white]{root_user.user_id}\")\n",
    "console.print(f\"Username: [bold cyan on white]{root_user.user_name}\")\n",
    "console.print(f\"ARN: [bold cyan on white]{root_user.arn}\")\n",
    "console.print(f\"AWS Account ID: [bold cyan on white]{aws_account_id}\")\n",
    "\n",
    "console.rule(\"IAM policy [cyan underline]crowd-workers-dev[/cyan underline]\")\n",
    "\n",
    "crowd_workers_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"allowBucketInteraction\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:PutObject\",\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                f\"arn:aws:s3:::{aws_private_bucket}\",\n",
    "                f\"arn:aws:s3:::{aws_private_bucket}/*\",\n",
    "                f\"arn:aws:s3:::{aws_deploy_bucket}\",\n",
    "                f\"arn:aws:s3:::{aws_deploy_bucket}/*\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"Sid\": \"allowDatabaseInteraction\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"dynamodb:DescribeTable\",\n",
    "                \"dynamodb:DeleteItem\",\n",
    "                \"dynamodb:PutItem\",\n",
    "                \"dynamodb:GetItem\",\n",
    "            ],\n",
    "            \"Resource\": f\"arn:aws:dynamodb:{aws_region}:{aws_account_id}:table/users\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "\n",
    "    ]\n",
    "}\n",
    "\n",
    "policy = None\n",
    "try:\n",
    "    policy = iam.create_policy(\n",
    "        PolicyName='crowd-workers-dev',\n",
    "        PolicyDocument=json.dumps(crowd_workers_policy)\n",
    "    )\n",
    "    console.print(\n",
    "        f\"[green]Policy creation completed[/green], HTTP STATUS CODE: {policy['ResponseMetadata']['HTTPStatusCode']}.\")\n",
    "except (iam.exceptions.EntityAlreadyExistsException) as exception:\n",
    "    console.print(f\"[yellow]Policy already present[/yellow]\")\n",
    "    policy = iam.get_policy(PolicyArn=f\"arn:aws:iam::{aws_account_id}:policy/crowd-workers-dev\")\n",
    "    console.print(\n",
    "        f\"[green]Policy retrieved[/green], HTTP STATUS CODE: {policy['ResponseMetadata']['HTTPStatusCode']}.\")\n",
    "serialize_json(folder_aws_path, f\"policy_{policy['Policy']['PolicyName']}.json\", policy)\n",
    "\n",
    "console.print(f\"Policy ARN: [cyan underline]{policy['Policy']['Arn']}[/cyan underline]\")\n",
    "\n",
    "console.rule(\"IAM user [cyan underline]worker-dev[/cyan underline]\")\n",
    "\n",
    "user = None\n",
    "try:\n",
    "    user = iam.create_user(UserName=\"worker-dev\")\n",
    "    console.print(\n",
    "        f\"[green]user created[/green], HTTP STATUS CODE: {user['ResponseMetadata']['HTTPStatusCode']}.\")\n",
    "except (iam.exceptions.EntityAlreadyExistsException) as exception:\n",
    "    console.print(f\"[yellow]User already present[/yellow]\")\n",
    "    user = iam.get_user(UserName=\"worker-dev\")\n",
    "    console.print(\n",
    "        f\"[green]User retrieved[green], HTTP STATUS CODE: {user['ResponseMetadata']['HTTPStatusCode']}.\")\n",
    "serialize_json(folder_aws_path, f\"user_{user['User']['UserName']}_data.json\", user)\n",
    "\n",
    "response = iam.attach_user_policy(UserName=user['User']['UserName'], PolicyArn=policy['Policy']['Arn'])\n",
    "policy = iam.get_policy(PolicyArn=f\"{policy['Policy']['Arn']}\")\n",
    "console.print(\n",
    "    f\"[green]Policy with ARN [cyan underline]{policy['Policy']['Arn']}[/cyan underline] attached to user, HTTP STATUS CODE: {user['ResponseMetadata']['HTTPStatusCode']}\")\n",
    "\n",
    "keys = []\n",
    "paginator = iam.get_paginator('list_access_keys')\n",
    "for found_keys in paginator.paginate(UserName=user['User']['UserName']):\n",
    "    for (index, key) in enumerate(found_keys['AccessKeyMetadata']):\n",
    "        keyData = read_json(f\"{folder_aws_path}user_{user['User']['UserName']}_access_key_{key['AccessKeyId']}.json\")\n",
    "        if keyData:\n",
    "            keys.append(keyData)\n",
    "        else:\n",
    "            response = iam.delete_access_key(UserName=user['User']['UserName'], AccessKeyId=key['AccessKeyId'])\n",
    "            console.print(f\"[red]Key {index} data not found on disk[/red]; deleting it on AWS, HTTP STATUS CODE: {response['ResponseMetadata']['HTTPStatusCode']}\")\n",
    "\n",
    "if len(keys) < 2:\n",
    "    key = iam.create_access_key(UserName=user['User']['UserName'])\n",
    "    serialize_json(folder_aws_path, f\"user_{user['User']['UserName']}_access_key_{key['AccessKey']['AccessKeyId']}.json\", key)\n",
    "    console.print(f\"[green]Access key created[/green], HTTP STATUS CODE: {key['ResponseMetadata']['HTTPStatusCode']}.\")\n",
    "    keys.append(key)\n",
    "    if not os.path.exists(f\"{folder_aws_path}user_{user['User']['UserName']}_access_key_{key['AccessKey']['AccessKeyId']}.json\"):\n",
    "        serialize_json(folder_aws_path, f\"user_{user['User']['UserName']}_access_key_{key['AccessKey']['AccessKeyId']}.json\", key)\n",
    "        console.print(f\"[green]Access key created[/green], HTTP STATUS CODE: {key['ResponseMetadata']['HTTPStatusCode']}.\")\n",
    "\n",
    "key_selected = random.choice(keys)\n",
    "key_data = read_json(f\"{folder_aws_path}user_{user['User']['UserName']}_access_key_{key_selected['AccessKey']['AccessKeyId']}.json\")\n",
    "\n",
    "console.print(\"Key data found on disk and loaded\")\n",
    "\n",
    "aws_worker_access_id = key_data['AccessKey']['AccessKeyId']\n",
    "aws_worker_access_secret = key_data['AccessKey']['SecretAccessKey']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Section 3 - Private and deploy bucket creation\n",
    "### build/aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "s3_resource = boto3.resource('s3')\n",
    "\n",
    "buckets = []\n",
    "for bucket in s3_resource.buckets.all():\n",
    "    buckets.append(bucket.name)\n",
    "\n",
    "console.rule(f\"bucket [cyan underline]{aws_private_bucket}[/cyan underline]\")\n",
    "\n",
    "try:\n",
    "    private_bucket = s3_client.create_bucket(\n",
    "        Bucket=aws_private_bucket,\n",
    "        CreateBucketConfiguration={\n",
    "            'LocationConstraint': aws_region\n",
    "        }\n",
    "    )\n",
    "    console.print(f\"[green]Bucket creation completed[/green], HTTP STATUS CODE: {private_bucket['ResponseMetadata']['HTTPStatusCode']}.\")\n",
    "except s3_client.exceptions.BucketAlreadyOwnedByYou as error:\n",
    "    private_bucket = s3_resource.Bucket(aws_private_bucket)\n",
    "    console.print(f\"[yellow]Bucket already present[/yellow], HTTP STATUS CODE: {error.response['ResponseMetadata']['HTTPStatusCode']}.\")\n",
    "serialize_json(folder_aws_path, f\"bucket_{aws_private_bucket}.json\", private_bucket)\n",
    "\n",
    "response = s3_client.put_public_access_block(\n",
    "    Bucket=aws_private_bucket,\n",
    "    PublicAccessBlockConfiguration={\n",
    "        'BlockPublicAcls': True,\n",
    "        'IgnorePublicAcls': True,\n",
    "        'BlockPublicPolicy': True,\n",
    "        'RestrictPublicBuckets': True\n",
    "    },\n",
    ")\n",
    "console.print(f\"[green]Public access blocked[/green], HTTP STATUS CODE: {response['ResponseMetadata']['HTTPStatusCode']}.\")\n",
    "\n",
    "private_bucket_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Id\": \"private-bucket-policy\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"allow-bucket-interaction\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"AWS\": f\"arn:aws:iam::{aws_account_id}:user/{user['User']['UserName']}\",\n",
    "            },\n",
    "            \"Action\": [\n",
    "                \"s3:PutObject\",\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                f\"arn:aws:s3:::{aws_private_bucket}\",\n",
    "                f\"arn:aws:s3:::{aws_private_bucket}/*\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "try:\n",
    "    policy = s3_client.get_bucket_policy(Bucket=aws_private_bucket)\n",
    "    policy['Policy'] = json.loads(policy['Policy'])\n",
    "    console.print(f\"[yellow]Policy already present[/yellow], HTTP STATUS CODE: {response['ResponseMetadata']['HTTPStatusCode']}.\")\n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'NoSuchBucketPolicy':\n",
    "        response = s3_client.put_bucket_policy(Bucket=aws_private_bucket, Policy=json.dumps(private_bucket_policy))\n",
    "        console.print(f\"[green]Policy configuration completed[/green], HTTP STATUS CODE: {response['ResponseMetadata']['HTTPStatusCode']}.\")\n",
    "    policy = s3_client.get_bucket_policy(Bucket=aws_private_bucket)\n",
    "    policy['Policy'] = json.loads(policy['Policy'])\n",
    "serialize_json(folder_aws_path, f\"bucket_{aws_private_bucket}_policy.json\", policy)\n",
    "\n",
    "cors_configuration = {\n",
    "    'CORSRules': [{\n",
    "        'AllowedHeaders': ['*'],\n",
    "        'AllowedMethods': ['GET', 'HEAD', 'PUT'],\n",
    "        'AllowedOrigins': ['*'],\n",
    "        'ExposeHeaders': [],\n",
    "        'MaxAgeSeconds': 3000\n",
    "    }]\n",
    "}\n",
    "\n",
    "try:\n",
    "    cors_configuration = s3_client.get_bucket_cors(Bucket=aws_private_bucket)\n",
    "    console.print(f\"[yellow]CORS Configuration already present[/yellow], HTTP STATUS CODE: {response['ResponseMetadata']['HTTPStatusCode']}.\")\n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'NoSuchCORSConfiguration':\n",
    "        response = s3_client.put_bucket_cors(Bucket=aws_private_bucket, CORSConfiguration=cors_configuration)\n",
    "        console.print(f\"[green]CORS configuration completed[green], HTTP STATUS CODE: {response['ResponseMetadata']['HTTPStatusCode']}.\")\n",
    "cors_configuration = s3_client.get_bucket_cors(Bucket=aws_private_bucket)\n",
    "serialize_json(folder_aws_path, f\"bucket_{aws_private_bucket}_cors.json\", cors_configuration)\n",
    "\n",
    "console.rule(f\"bucket [cyan underline]{aws_deploy_bucket}[/cyan underline]\")\n",
    "\n",
    "try:\n",
    "    deploy_bucket = s3_client.create_bucket(\n",
    "        Bucket=aws_deploy_bucket,\n",
    "        CreateBucketConfiguration={\n",
    "            'LocationConstraint': aws_region\n",
    "        }\n",
    "    )\n",
    "    console.print(f\"[green]Bucket creation completed[/green], HTTP STATUS CODE: {deploy_bucket['ResponseMetadata']['HTTPStatusCode']}.\")\n",
    "except s3_client.exceptions.BucketAlreadyOwnedByYou as error:\n",
    "    deploy_bucket = s3_resource.Bucket(aws_deploy_bucket)\n",
    "    console.print(f\"[yellow]Bucket already present[/yellow], HTTP STATUS CODE: {error.response['ResponseMetadata']['HTTPStatusCode']}.\")\n",
    "serialize_json(folder_aws_path, f\"bucket_{aws_deploy_bucket}.json\", deploy_bucket)\n",
    "\n",
    "deploy_bucket_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Id\": \"deploy-bucket-policy\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"allow-bucket-interaction\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"AWS\": f\"arn:aws:iam::{aws_account_id}:user/{user['User']['UserName']}\"\n",
    "            },\n",
    "            \"Action\": [\n",
    "                \"s3:PutObject\",\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                f\"arn:aws:s3:::{aws_deploy_bucket}\",\n",
    "                f\"arn:aws:s3:::{aws_deploy_bucket}/*\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"Sid\": \"allow-bucket-administration\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"AWS\": root_user.arn\n",
    "            },\n",
    "            \"Action\": [\n",
    "                \"s3:*\",\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                f\"arn:aws:s3:::{aws_deploy_bucket}\",\n",
    "                f\"arn:aws:s3:::{aws_deploy_bucket}/*\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "try:\n",
    "    policy = s3_client.get_bucket_policy(Bucket=aws_deploy_bucket)\n",
    "    policy['Policy'] = json.loads(policy['Policy'])\n",
    "    console.print(f\"[yellow]Policy already present[/yellow], HTTP STATUS CODE: {response['ResponseMetadata']['HTTPStatusCode']}.\")\n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'NoSuchBucketPolicy':\n",
    "        response = s3_client.put_bucket_policy(Bucket=aws_deploy_bucket, Policy=json.dumps(deploy_bucket_policy))\n",
    "        console.print(f\"[green]Policy configuration completed[/green], HTTP STATUS CODE: {response['ResponseMetadata']['HTTPStatusCode']}.\")\n",
    "    policy = s3_client.get_bucket_policy(Bucket=aws_deploy_bucket)\n",
    "    policy['Policy'] = json.loads(policy['Policy'])\n",
    "serialize_json(folder_aws_path, f\"bucket_{aws_private_bucket}_policy.json\", policy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Section 4 - Environment file generation\n",
    "### build/environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "environment_development = f\"{folder_build_path}environments/environment.ts\"\n",
    "environment_production = f\"{folder_build_path}environments/environment.prod.ts\"\n",
    "\n",
    "console.rule(\"Environment: [cyan underline]PRODUCTION[/cyan underline]\")\n",
    "\n",
    "environment_dict = {\n",
    "    \"production\": 'true',\n",
    "    \"configuration_local\": 'false',\n",
    "    \"taskName\": task_name,\n",
    "    \"batchName\": batch_name,\n",
    "    \"region\": aws_region,\n",
    "    \"bucket\": aws_private_bucket,\n",
    "    \"aws_id_key\": aws_worker_access_id,\n",
    "    \"aws_secret_key\": aws_worker_access_secret,\n",
    "    \"bing_api_key\": bing_api_key\n",
    "}\n",
    "\n",
    "with open(environment_production, 'w') as file:\n",
    "    print(\"export const environment = {\", file=file)\n",
    "    for (env_var, value) in environment_dict.items():\n",
    "        if env_var == 'production' or env_var == 'configuration_local':\n",
    "            print(f\"\\t{env_var}: {value},\", file=file)\n",
    "        else:\n",
    "            print(f\"\\t{env_var}: \\\"{value}\\\",\", file=file)\n",
    "    print(\"};\", file=file)\n",
    "\n",
    "console.print(\"File [cyan underline]environment.prod.ts[/cyan underline] generated\")\n",
    "console.print(f\"Path: [italic]{environment_production}[/italic]\")\n",
    "\n",
    "console.rule(\"Environment: [cyan underline]DEVELOPMENT[/cyan underline]\")\n",
    "\n",
    "environment_dict = {\n",
    "    \"production\": 'false',\n",
    "    \"configuration_local\": 'true',\n",
    "    \"taskName\": task_name,\n",
    "    \"batchName\": batch_name,\n",
    "    \"region\": aws_region,\n",
    "    \"bucket\": aws_private_bucket,\n",
    "    \"aws_id_key\": aws_worker_access_id,\n",
    "    \"aws_secret_key\": aws_worker_access_secret,\n",
    "    \"bing_api_key\": bing_api_key\n",
    "}\n",
    "\n",
    "with open(environment_development, 'w') as file:\n",
    "    print(\"export const environment = {\", file=file)\n",
    "    for (env_var, value) in environment_dict.items():\n",
    "        if env_var == 'production' or env_var == 'configuration_local':\n",
    "            print(f\"\\t{env_var}: {value},\", file=file)\n",
    "        else:\n",
    "            print(f\"\\t{env_var}: \\\"{value}\\\",\", file=file)\n",
    "    print(\"};\", file=file)\n",
    "\n",
    "console.print(\"File [cyan underline]environment.ts[/cyan underline] generated\")\n",
    "console.print(f\"Path: [italic]{environment_development}[/italic]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Section 5 - admin.json file generation\n",
    "### build/config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import hmac\n",
    "import hashlib\n",
    "\n",
    "console.rule(\"File [cyan underline]admin.json\")\n",
    "\n",
    "if not os.path.exists(folder_build_config_path):\n",
    "    os.makedirs(folder_build_config_path, exist_ok=True)\n",
    "\n",
    "admin_file = f\"{folder_build_config_path}admin.json\"\n",
    "\n",
    "console.print(\"Creating hash with [cyan underline]hmac[/cyan underline] and [cyan underline]sha256[/cyan underline]\")\n",
    "console.print(f\"Processing user with username: [white on purple]{admin_user}[white on purple]\")\n",
    "\n",
    "admins = []\n",
    "body = f\"username:{admin_user}\"\n",
    "digest_maker = hmac.new(admin_password.encode(), body.encode(), hashlib.sha256)\n",
    "admins.append(digest_maker.hexdigest())\n",
    "with open(admin_file, 'w') as file:\n",
    "    json.dump(admins, file, indent=4)\n",
    "\n",
    "console.print(f\"Path: [italic]{admin_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Section 6 - document.ts file generation\n",
    "### build/skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "console.rule(\"Interface [cyan underline]document.ts\")\n",
    "\n",
    "hits_file = f\"{folder_build_task_path}hits.json\"\n",
    "document_interface = f\"{folder_build_skeleton_path}document.ts\"\n",
    "if not os.path.exists(folder_build_skeleton_path):\n",
    "    os.makedirs(folder_build_skeleton_path, exist_ok=True)\n",
    "\n",
    "console.print(f\"Reading hits file\")\n",
    "console.print(f\"Path: [italic]{hits_file}[/italic]\")\n",
    "hits = read_json(hits_file)\n",
    "sample_element = hits.pop()['documents'].pop()\n",
    "\n",
    "if not 'id' in sample_element.keys():\n",
    "    raise Exception(\"[red]Your [underline]hits.json[/underline] file contains an attributed called [underline]\\\"id\\\"[/underline]?\")\n",
    "\n",
    "# This class provides a representation of a single document stored in single hit stored in the Amazon S3 bucket.\n",
    "# The attribute <document_index> is additional and should not be touched and passed in the constructor.\n",
    "# Each field of such Document must be mapped to an attribute of this class and set up in the constructor as it is shown.\n",
    "\n",
    "with open(document_interface, 'w') as file:\n",
    "    print(\"export class Document {\", file=file)\n",
    "    print(\"\", file=file)\n",
    "    wrapper = textwrap.TextWrapper(initial_indent='\\t\\t', subsequent_indent='\\t\\t')\n",
    "    print(wrapper.fill(\"index: number;\"), file=file)\n",
    "    print(wrapper.fill(\"countdownExpired: boolean;\"), file=file)\n",
    "    for attribute, value in sample_element.items():\n",
    "        try:\n",
    "            element = json.loads(value)\n",
    "            if isinstance(element, dict):\n",
    "                print(wrapper.fill(f\"{attribute}: Array<JSON>;\"), file=file)\n",
    "            elif isinstance(element, int) or isinstance(element, float):\n",
    "                if(attribute==\"id\"):\n",
    "                    print(wrapper.fill(f\"{attribute}: string;\"), file=file)\n",
    "                else:\n",
    "                    print(wrapper.fill(f\"{attribute}: number;\"), file=file)\n",
    "            elif isinstance(element, list):\n",
    "                print(wrapper.fill(f\"{attribute}: Array<String>;\"), file=file)\n",
    "            else:\n",
    "                print(wrapper.fill(f\"{attribute}: string;\"), file=file)\n",
    "            console.print(f\"Attribute with name: [cyan underline]{attribute}[/cyan underline] and type: {type(element)} found\")\n",
    "        except (TypeError, ValueError) as e:\n",
    "            if isinstance(value, list):\n",
    "                print(wrapper.fill(f\"{attribute}: Array<String>;\"), file=file)\n",
    "            elif isinstance(value, int) or isinstance(value, float):\n",
    "                print(wrapper.fill(f\"{attribute}: number;\"), file=file)\n",
    "            else:\n",
    "                print(wrapper.fill(f\"{attribute}: string;\"), file=file)\n",
    "            console.print(f\"Attribute with name: [cyan underline]{attribute}[/cyan underline] and type: {type(value)} found\")\n",
    "    print(\"\", file=file)\n",
    "    print(wrapper.fill(f\"constructor (\"), file=file)\n",
    "    wrapper = textwrap.TextWrapper(initial_indent='\\t\\t\\t', subsequent_indent='\\t\\t\\t')\n",
    "    print(wrapper.fill(\"index: number,\"), file=file)\n",
    "    print(wrapper.fill(\"data: JSON\"), file=file)\n",
    "    wrapper = textwrap.TextWrapper(initial_indent='\\t\\t', subsequent_indent='\\t\\t')\n",
    "    print(wrapper.fill(\") {\"), file=file)\n",
    "    print(\"\", file=file)\n",
    "    wrapper = textwrap.TextWrapper(initial_indent='\\t\\t\\t', subsequent_indent='\\t\\t\\t')\n",
    "    print(wrapper.fill(\"this.index = index\"), file=file)\n",
    "    for attribute, value in sample_element.items():\n",
    "        try:\n",
    "            element = json.loads(value)\n",
    "            if isinstance(element, dict):\n",
    "                print(wrapper.fill(f\"this.{attribute} = new Array<JSON>()\"), file=file)\n",
    "                print(wrapper.fill(f\"for (let index = 0; index < data[\\\"{attribute}\\\"].length; index++) this.{attribute}.push(data[\\\"{attribute}\\\"][index])\"), file=file)\n",
    "            elif isinstance(element, list):\n",
    "                print(wrapper.fill(f\"this.{attribute} = new Array<String>()\"), file=file)\n",
    "                print(wrapper.fill(f\"for (let index = 0; index < data[\\\"{attribute}\\\"].length; index++) this.{attribute}.push(data[\\\"{attribute}\\\"])\"), file=file)\n",
    "            else:\n",
    "                wrapper = textwrap.TextWrapper(initial_indent='\\t\\t\\t', subsequent_indent='\\t\\t\\t')\n",
    "                print(wrapper.fill(f\"this.{attribute} = data[\\\"{attribute}\\\"]\"), file=file)\n",
    "        except (TypeError, ValueError) as e:\n",
    "            if isinstance(value, list):\n",
    "                print(wrapper.fill(f\"this.{attribute} = new Array<String>()\"), file=file)\n",
    "                print(wrapper.fill(f\"for (let index = 0; index < data[\\\"{attribute}\\\"].length; index++) this.{attribute}.push(data[\\\"{attribute}\\\"])\"), file=file)\n",
    "            else:\n",
    "                wrapper = textwrap.TextWrapper(initial_indent='\\t\\t\\t', subsequent_indent='\\t\\t\\t')\n",
    "                print(wrapper.fill(f\"this.{attribute} = data[\\\"{attribute}\\\"]\"), file=file)\n",
    "    wrapper = textwrap.TextWrapper(initial_indent='\\t\\t', subsequent_indent='\\t\\t')\n",
    "    print(\"\", file=file)\n",
    "    print(wrapper.fill(\"}\"), file=file)\n",
    "    print(\"\", file=file)\n",
    "    print(\"}\", file=file)\n",
    "\n",
    "console.print(\"Interface built\")\n",
    "console.print(f\"Path: [italic]{document_interface}[/italic]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7 - Amazon Mechanical Turk assets generation\n",
    "### build/mturk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from mako.template import Template\n",
    "\n",
    "console.rule(\"Amazon Mechanical Turk landing page\")\n",
    "\n",
    "model = Template(filename=f\"{folder_build_mturk_path}model.html\")\n",
    "mturk_page = model.render(\n",
    "    aws_region = aws_region,\n",
    "    aws_deploy_bucket = aws_deploy_bucket,\n",
    "    task_name = task_name,\n",
    "    batch_name = batch_name\n",
    ")\n",
    "mturk_page_file = f\"{folder_build_mturk_path}index.html\"\n",
    "with open(mturk_page_file, 'w') as file:\n",
    "    print(mturk_page, file=file)\n",
    "\n",
    "console.print(f\"Model istantiated\")\n",
    "console.print(f\"Path: {mturk_page_file}\")\n",
    "\n",
    "hits_file = f\"{folder_build_task_path}hits.json\"\n",
    "mturk_tokens_file = f\"{folder_build_mturk_path}tokens.csv\"\n",
    "console.print(f\"Loading [cyan underline]hits.json[/cyan underline] file\")\n",
    "console.print(f\"Path: [ital]{hits_file}\")\n",
    "hits = read_json(hits_file)\n",
    "token_df = pd.DataFrame(columns=[\"token_input\", \"token_output\"])\n",
    "for hit in hits:\n",
    "    token_df = token_df.append({\n",
    "        \"token_input\": hit['token_input'],\n",
    "        \"token_output\": hit['token_output']\n",
    "    }, ignore_index=True)\n",
    "token_df.to_csv(mturk_tokens_file, index=False)\n",
    "console.print(f\"Tokens for {len(hits)} generated\")\n",
    "console.print(f\"Path: [italic]{mturk_tokens_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 8 - Angular Application Build\n",
    "### build/deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import shutil\n",
    "from mako.template import Template\n",
    "import time\n",
    "\n",
    "folder_build_result = f\"../dist/\"\n",
    "\n",
    "console.rule(f\"Task [cyan underline]{task_name}[/cyan underline]/[yellow underline]{batch_name}[/yellow underline] build\")\n",
    "\n",
    "console.print(\"Executing command\")\n",
    "command = \"ng build --configuration=\\\"production\\\" --output-hashing=none\"\n",
    "console.print(f\"[green on black]{command}\")\n",
    "console.print(f\"Please wait...\")\n",
    "process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE)\n",
    "for line in process.stdout:\n",
    "    line_clean = line.decode().strip()\n",
    "    if \"Initial Total\" in line_clean:\n",
    "        line_clean = line_clean[2:]\n",
    "    if line_clean!=\"\":\n",
    "        console.print(line_clean)\n",
    "process.wait()\n",
    "\n",
    "console.print(\"Merging Javascript assets\")\n",
    "script_merged_file = f\"{folder_build_deploy_path}scripts.js\"\n",
    "if(os.path.exists(script_merged_file)):\n",
    "    os.remove(script_merged_file)\n",
    "es_scripts = [\n",
    "    'polyfills.js',\n",
    "    'runtime.js',\n",
    "    'main.js',\n",
    "]\n",
    "with open(script_merged_file, 'a') as outfile:\n",
    "    for file in es_scripts:\n",
    "        script_current_file = f\"{folder_build_result}Crowd_Frame/{file}\"\n",
    "        console.print(f\"Processing file: [italic purple on black]{script_current_file}\")\n",
    "        with open(script_current_file) as script:\n",
    "            for line in script:\n",
    "                outfile.write(line)\n",
    "console.print(f\"Path: [italic]{script_merged_file}\")\n",
    "\n",
    "console.print(\"Merging CSS assets\")\n",
    "styles_merged_file = f\"{folder_build_deploy_path}styles.css\"\n",
    "if(os.path.exists(styles_merged_file)):\n",
    "    os.remove(styles_merged_file)\n",
    "css_styles = ['styles.css']\n",
    "with open(styles_merged_file, 'a') as outfile:\n",
    "    for file in css_styles:\n",
    "        style_current_file = f\"{folder_build_result}Crowd_Frame/{file}\"\n",
    "        console.print(f\"Processing file: [italic cyan on black]{style_current_file}\")\n",
    "        with open(style_current_file) as style:\n",
    "            for line in style:\n",
    "                outfile.write(line)\n",
    "console.print(f\"Path: [italic underline]{styles_merged_file}\")\n",
    "\n",
    "console.print(\"Deleting build folder\")\n",
    "console.print(f\"Path: [italic underline]{folder_build_result}\")\n",
    "shutil.rmtree(folder_build_result)\n",
    "\n",
    "model = Template(filename=f\"{folder_build_deploy_path}model.html\")\n",
    "index_page = model.render(\n",
    "    task_name = task_name,\n",
    "    batch_name = batch_name\n",
    ")\n",
    "index_page_file = f\"{folder_build_deploy_path}index.html\"\n",
    "with open(index_page_file, 'w') as file:\n",
    "    print(index_page, file=file)\n",
    "\n",
    "console.print(\"Model istantiated\")\n",
    "console.print(f\"Path: [italic underline]{index_page_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Section 9 - Packaging\n",
    "### tasks/task_name/batch_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from shutil import copy2\n",
    "\n",
    "console.rule(f\"Packaging task in [cyan underline]tasks/{task_name}/{batch_name}\")\n",
    "\n",
    "folder_tasks_batch_path = f\"{folder_tasks_path}{task_name}/{batch_name}/\"\n",
    "folder_tasks_batch_deploy_path = f\"{folder_tasks_batch_path}deploy/\"\n",
    "folder_tasks_batch_mturk_path = f\"{folder_tasks_batch_path}mturk/\"\n",
    "folder_tasks_batch_task_path = f\"{folder_tasks_batch_path}task/\"\n",
    "folder_tasks_batch_config_path = f\"{folder_tasks_batch_path}config/\"\n",
    "\n",
    "console.print(f\"[italic purple]deploy-config[/italic purple] variable: {bool(deploy_config)}\")\n",
    "\n",
    "if not os.path.exists(folder_tasks_batch_deploy_path):\n",
    "    console.print(\"[green]Deploy folder created\")\n",
    "    os.makedirs(folder_tasks_batch_deploy_path, exist_ok=True)\n",
    "else:\n",
    "    console.print(\"[yellow]Deploy folder already present\")\n",
    "console.print(f\"Path: [italic]{folder_tasks_batch_deploy_path}\")\n",
    "if not os.path.exists(folder_tasks_batch_mturk_path):\n",
    "    console.print(\"[green]Amazon Mechanical Turk assets folder created\")\n",
    "    os.makedirs(folder_tasks_batch_mturk_path, exist_ok=True)\n",
    "else:\n",
    "    console.print(\"[yellow]Amazon Mechanical Turk assets folder already present\")\n",
    "console.print(f\"Path: [italic]{folder_tasks_batch_mturk_path}\")\n",
    "if not os.path.exists(folder_tasks_batch_task_path) and deploy_config:\n",
    "    console.print(\"[green]Task configuration folder created\")\n",
    "    os.makedirs(folder_tasks_batch_task_path, exist_ok=True)\n",
    "else:\n",
    "    console.print(\"[yellow]Task configuration folder already present\")\n",
    "console.print(f\"Path: [italic]{folder_tasks_batch_task_path}\")\n",
    "if not os.path.exists(folder_tasks_batch_config_path) and deploy_config:\n",
    "    console.print(\"[green]Task configuration folder created\")\n",
    "    os.makedirs(folder_tasks_batch_config_path, exist_ok=True)\n",
    "else:\n",
    "    console.print(\"[yellow]General configuration folder already present\")\n",
    "console.print(f\"Path: [italic]{folder_tasks_batch_config_path}\")\n",
    "\n",
    "def copy(source, destination, title):\n",
    "    panel = Panel(f\"Source: [italic white on black]{source}[/italic white on black]\\nDestination: [italic white on black]{destination}[/italic white on black]\", title=title)\n",
    "    console.print(panel)\n",
    "    copy2(source, destination)\n",
    "\n",
    "console.print(f\"Copying files for [blue underline on white]{folder_build_deploy_path}[/blue underline on white] folder\")\n",
    "\n",
    "source = f\"{folder_build_deploy_path}scripts.js\"\n",
    "destination = f\"{folder_tasks_batch_deploy_path}scripts.js\"\n",
    "copy(source, destination, \"Javascript Assets\")\n",
    "\n",
    "source = f\"{folder_build_deploy_path}styles.css\"\n",
    "destination = f\"{folder_tasks_batch_deploy_path}styles.css\"\n",
    "copy(source, destination, \"CSS Styles\")\n",
    "\n",
    "source = f\"{folder_build_deploy_path}index.html\"\n",
    "destination = f\"{folder_tasks_batch_deploy_path}index.html\"\n",
    "copy(source, destination, \"Task Homepage\")\n",
    "\n",
    "console.print(f\"Copying files for [blue underline on white]{folder_build_mturk_path}[/blue underline on white] folder\")\n",
    "\n",
    "source = f\"{folder_build_mturk_path}index.html\"\n",
    "destination = f\"{folder_tasks_batch_mturk_path}index.html\"\n",
    "copy(source, destination, \"Amazon Mechanical Turk landing page\")\n",
    "\n",
    "source = f\"{folder_build_mturk_path}tokens.csv\"\n",
    "destination = f\"{folder_tasks_batch_mturk_path}tokens.csv\"\n",
    "copy(source, destination, \"Hits tokens\")\n",
    "\n",
    "if bool(deploy_config):\n",
    "\n",
    "    console.print(f\"Copying files for [blue underline on white]{folder_build_task_path}[/blue underline on white] folder\")\n",
    "\n",
    "    source = f\"{folder_build_task_path}hits.json\"\n",
    "    destination = f\"{folder_tasks_batch_task_path}hits.json\"\n",
    "    copy(source, destination, \"Hits\")\n",
    "\n",
    "    source = f\"{folder_build_task_path}dimensions.json\"\n",
    "    destination = f\"{folder_tasks_batch_task_path}dimensions.json\"\n",
    "    copy(source, destination, \"Dimensions\")\n",
    "\n",
    "    source = f\"{folder_build_task_path}instructions_dimensions.json\"\n",
    "    destination = f\"{folder_tasks_batch_task_path}instructions_dimensions.json\"\n",
    "    copy(source, destination, \"Assessment Instructions\")\n",
    "\n",
    "    source = f\"{folder_build_task_path}instructions_main.json\"\n",
    "    destination = f\"{folder_tasks_batch_task_path}instructions_main.json\"\n",
    "    copy(source, destination, \"General Instructions\")\n",
    "\n",
    "    source = f\"{folder_build_task_path}questionnaires.json\"\n",
    "    destination = f\"{folder_tasks_batch_task_path}questionnaires.json\"\n",
    "    copy(source, destination, \"Questionnaires\")\n",
    "\n",
    "    source = f\"{folder_build_task_path}search_engine.json\"\n",
    "    destination = f\"{folder_tasks_batch_task_path}search_engine.json\"\n",
    "    copy(source, destination, \"Search Engine\")\n",
    "\n",
    "    source = f\"{folder_build_task_path}task.json\"\n",
    "    destination = f\"{folder_tasks_batch_task_path}task.json\"\n",
    "    copy(source, destination, \"Task Settings\")\n",
    "\n",
    "    source = f\"{folder_build_task_path}workers.json\"\n",
    "    destination = f\"{folder_tasks_batch_task_path}workers.json\"\n",
    "    copy(source, destination, \"Workers Settings\")\n",
    "\n",
    "source = f\"{folder_build_config_path}admin.json\"\n",
    "destination = f\"{folder_tasks_batch_config_path}admin.json\"\n",
    "copy(source, destination, \"Admin Credentials\")\n",
    "\n",
    "console.print(f\"Copying files for [blue underline on white]{folder_tasks_batch_config_path}[/blue underline on white] folder\")"
   ]
  },
  {
   "source": [
    "## Section 10 - Deploy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "s3_private_generator_path = f\"{task_name}/{batch_name}/Generator/\"\n",
    "s3_private_task_path = f\"{task_name}/{batch_name}/Task/\"\n",
    "s3_deploy_path = f\"{task_name}/{batch_name}/\"\n",
    "\n",
    "folder_tasks_batch_deploy_path = f\"{folder_tasks_batch_path}deploy/\"\n",
    "folder_tasks_batch_mturk_path = f\"{folder_tasks_batch_path}mturk/\"\n",
    "folder_tasks_batch_task_path = f\"{folder_tasks_batch_path}task/\"\n",
    "folder_tasks_batch_config_path = f\"{folder_tasks_batch_path}config/\"\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "def upload(path, bucket, key, title, content_type, acl=None):\n",
    "    panel = Panel(f\"Region: [italic white on black]{aws_region}[/italic white on black]\\nBucket: [italic white on black]{bucket}[/italic white on black]\\nFile: [italic white on black]{path}[/italic white on black]\\nKey: [italic white on black]{key}[/italic white on black]\\nPath: [italic white on black] s3://{aws_region}/{bucket}/{key}[/italic white on black]\\nACL: {acl}\", title=title)\n",
    "    console.print(panel)\n",
    "    if acl:\n",
    "        response = s3_client.put_object(Body=open(path, 'rb'), Bucket=bucket, Key=key, ContentType=content_type, ACL=acl)\n",
    "    else:\n",
    "        response = s3_client.put_object(Body=open(path, 'rb'), Bucket=bucket, Key=key, ContentType=content_type)\n",
    "    console.print(f\"HTTP Status Code: {response['ResponseMetadata']['HTTPStatusCode']}, ETag: {response['ETag']}\")\n",
    "\n",
    "console.rule(f\"Task [cyan underline]{task_name}[/cyan underline]/[yellow underline]{batch_name}[/yellow underline] deploy\")\n",
    "\n",
    "console.print(f\"[italic purple]deploy-config[/italic purple] variable: {bool(deploy_config)}\")\n",
    "\n",
    "console.print(f\"[white on blue bold]Generator configuration\")\n",
    "\n",
    "path = f\"{folder_tasks_batch_config_path}admin.json\"\n",
    "key = f\"{s3_private_generator_path}admin.json\"\n",
    "upload(path, aws_private_bucket, key, \"Admin Credentials\", \"application/json\")\n",
    "\n",
    "if bool(deploy_config):\n",
    "\n",
    "    console.print(f\"[white on green bold]Task configuration\")\n",
    "\n",
    "    path = f\"{folder_tasks_batch_task_path}hits.json\"\n",
    "    key = f\"{s3_private_task_path}hits.json\"\n",
    "    upload(path, aws_private_bucket, key, \"Hits\", \"application/json\")\n",
    "\n",
    "    path = f\"{folder_tasks_batch_task_path}instructions_dimensions.json\"\n",
    "    key = f\"{s3_private_task_path}instructions_dimensions.json\"\n",
    "    upload(path, aws_private_bucket, key, \"Assessment Instructions\", \"application/json\")\n",
    "\n",
    "    path = f\"{folder_tasks_batch_task_path}instructions_main.json\"\n",
    "    key = f\"{s3_private_task_path}instructions_main.json\"\n",
    "    upload(path, aws_private_bucket, key, \"General Instructions\", \"application/json\")\n",
    "\n",
    "    path = f\"{folder_tasks_batch_task_path}questionnaires.json\"\n",
    "    key = f\"{s3_private_task_path}questionnaires.json\"\n",
    "    upload(path, aws_private_bucket, key, \"Questionnaires\", \"application/json\")\n",
    "\n",
    "    path = f\"{folder_tasks_batch_task_path}dimensions.json\"\n",
    "    key = f\"{s3_private_task_path}dimensions.json\"\n",
    "    upload(path, aws_private_bucket, key, \"Dimensions\", \"application/json\")\n",
    "\n",
    "    path = f\"{folder_tasks_batch_task_path}search_engine.json\"\n",
    "    key = f\"{s3_private_task_path}search_engine.json\"\n",
    "    upload(path, aws_private_bucket, key, \"Search Engine\", \"application/json\")\n",
    "\n",
    "    path = f\"{folder_tasks_batch_task_path}task.json\"\n",
    "    key = f\"{s3_private_task_path}task.json\"\n",
    "    upload(path, aws_private_bucket, key, \"Task Settings\", \"application/json\")\n",
    "\n",
    "    path = f\"{folder_tasks_batch_task_path}workers.json\"\n",
    "    key = f\"{s3_private_task_path}workers.json\"\n",
    "    upload(path, aws_private_bucket, key, \"Workers Settings\", \"application/json\")\n",
    "\n",
    "console.print(f\"[white on purple bold]Angular Application\")\n",
    "\n",
    "path = f\"{folder_tasks_batch_deploy_path}scripts.js\"\n",
    "key = f\"{s3_deploy_path}scripts.js\"\n",
    "upload(path, aws_deploy_bucket, key, \"Javascript Assets\", \"text/javascript\", \"public-read\")\n",
    "\n",
    "path = f\"{folder_tasks_batch_deploy_path}styles.css\"\n",
    "key = f\"{s3_deploy_path}styles.css\"\n",
    "upload(path, aws_deploy_bucket, key, \"CSS Styles\", \"text/css\", \"public-read\")\n",
    "\n",
    "path = f\"{folder_tasks_batch_deploy_path}index.html\"\n",
    "key = f\"{s3_deploy_path}index.html\"\n",
    "upload(path, aws_deploy_bucket, key, \"Task Homepage\",  \"text/html\", \"public-read\")\n",
    "\n",
    "console.rule(\"Link\")\n",
    "\n",
    "console.print(f\"[bold cyan on black]https://{aws_deploy_bucket}.s3.{aws_region}.amazonaws.com/{task_name}/{batch_name}/index.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}